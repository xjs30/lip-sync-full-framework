import os
import torch
import numpy as np
import gradio as gr
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import uvicorn
import tempfile
import cv2
from datetime import datetime
import asyncio
from models.latent_diffusion import LatentDiffusionModel
from utils.audio_processor import AudioProcessor
from utils.video_processor import VideoProcessor

# åˆå§‹åŒ–åº”ç”¨
app = FastAPI(title="LatentSyncé£æ ¼å¯¹å£å‹ç³»ç»Ÿ")
processor = gr.Blocks(title="æ™ºèƒ½å”‡å½¢åŒæ­¥ç³»ç»Ÿ")

# é…ç½®
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "pretrained/latent_sync_model.pth"
OUTPUT_DIR = "outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
audio_processor = AudioProcessor()
video_processor = VideoProcessor()

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
print(f"åŠ è½½æ¨¡å‹åˆ° {DEVICE}...")
model = LatentDiffusionModel(image_size=64)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model = model.to(DEVICE).eval()
print("æ¨¡å‹åŠ è½½å®Œæˆ")

# å¤„ç†å‡½æ•°
def process_lip_sync(video_path, audio_path, progress=gr.Progress()):
    try:
        # 1. é¢„å¤„ç†
        progress(0, desc="å¤„ç†è¾“å…¥æ•°æ®")
        video_frames, fps = video_processor.load_video(video_path)
        audio_features = audio_processor.extract_features(audio_path)
        
        # 2. æå–é¢éƒ¨ç‰¹å¾
        progress(0.3, desc="æå–é¢éƒ¨ç‰¹å¾")
        face_features = video_processor.extract_face_features(video_frames)
        
        # 3. æ¨¡å‹æ¨ç†
        progress(0.5, desc="ç”Ÿæˆå”‡å½¢åŒæ­¥è§†é¢‘")
        with torch.no_grad():
            # è½¬æ¢ä¸ºå¼ é‡
            audio_tensor = torch.tensor(audio_features, dtype=torch.float32).unsqueeze(0).to(DEVICE)
            face_tensor = torch.tensor(face_features, dtype=torch.float32).unsqueeze(0).to(DEVICE)
            
            # ç”Ÿæˆè§†é¢‘
            output_tensor = model.sample(
                audio_feat=audio_tensor,
                face_feat=face_tensor,
                num_steps=30
            )
        
        # 4. åå¤„ç†
        progress(0.8, desc="å¤„ç†è¾“å‡ºè§†é¢‘")
        output_frames = output_tensor.squeeze(0).cpu().numpy()
        output_frames = video_processor.postprocess_frames(output_frames, video_frames)
        
        # 5. ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(OUTPUT_DIR, f"result_{timestamp}.mp4")
        video_processor.save_video(output_frames, fps, audio_path, output_path)
        
        progress(1.0, desc="å®Œæˆ")
        return output_path
        
    except Exception as e:
        print(f"å¤„ç†é”™è¯¯: {str(e)}")
        raise gr.Error(f"å¤„ç†å¤±è´¥: {str(e)}")

# æ„å»ºGradioç•Œé¢
with processor:
    gr.Markdown("# ğŸ­ æ™ºèƒ½å”‡å½¢åŒæ­¥ç³»ç»Ÿ")
    gr.Markdown("åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„éŸ³é¢‘é©±åŠ¨å”‡å½¢ç”Ÿæˆï¼Œä¸LatentSyncé‡‡ç”¨ç›¸åŒæŠ€æœ¯è·¯çº¿")
    
    with gr.Row():
        with gr.Column(scale=1):
            video_input = gr.Video(label="è¾“å…¥è§†é¢‘")
            audio_input = gr.Audio(label="è¾“å…¥éŸ³é¢‘", type="filepath")
            generate_btn = gr.Button("ç”ŸæˆåŒæ­¥è§†é¢‘", variant="primary")
        
        with gr.Column(scale=1):
            video_output = gr.Video(label="è¾“å‡ºè§†é¢‘")
    
    generate_btn.click(
        fn=process_lip_sync,
        inputs=[video_input, audio_input],
        outputs=video_output
    )
    
    gr.Markdown("""
    ### æŠ€æœ¯è¯´æ˜
    - é‡‡ç”¨éŸ³é¢‘é©±åŠ¨çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹
    - é›†æˆTREPAæ—¶é—´ä¸€è‡´æ€§ä¼˜åŒ–
    - ä½¿ç”¨SyncNetç›‘ç£æœºåˆ¶ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
    """)

# APIç«¯ç‚¹
@app.post("/api/generate")
async def api_generate(video: UploadFile = File(...), audio: UploadFile = File(...)):
    # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as vf, \
         tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as af:
        
        vf.write(await video.read())
        af.write(await audio.read())
        video_path = vf.name
        audio_path = af.name
    
    # å¤„ç†
    output_path = process_lip_sync(video_path, audio_path)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.unlink(video_path)
    os.unlink(audio_path)
    
    return FileResponse(output_path)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", choices=["web", "api"], default="web")
    parser.add_argument("--port", type=int, default=7860)
    args = parser.parse_args()
    
    if args.mode == "web":
        processor.launch(server_name="0.0.0.0", server_port=args.port)
    else:
        uvicorn.run(app, host="0.0.0.0", port=args.port)
